# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-UirUZrqpnfx61Mxa2rM40ODeGcKVrUB
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report

df = pd.read_excel('edit.xlsx')

# Drop first metadata row
df = df.drop(index=0).reset_index(drop=True)

# Rename columns
df.columns = [
    'Audio', 'Label', 'Start', 'End', 'Gender',
    'Pitch_Median', 'Pitch_Mean', 'Pitch_Max', 'Pitch_Min',
    'Pitch_Std', 'Jitter_Local', 'Jitter_RAP', 'Jitter_PPQ5',
    'Shimmer_Local', 'Shimmer_dB', 'Shimmer_APQ3',
    'HNR', 'NHR', 'Unvoiced_Frames',
    'Voice_Breaks', 'Speaker'
]

# Drop unusable columns
df = df.drop(columns=['Audio', 'Start', 'End', 'Speaker', 'Gender'])

for col in df.columns:
    if col != 'Label':
        df[col] = pd.to_numeric(df[col], errors='coerce')

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Label'] = le.fit_transform(df['Label'])

X = df.drop(columns='Label')
y = df['Label']

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42
)

rf_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier(
        n_estimators=100,
        max_depth=None,
        class_weight='balanced',
        random_state=42
    ))
])

rf_pipeline.fit(X_train, y_train)

y_pred = rf_pipeline.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy*100:.2f}%")

f1 = f1_score(y_test, y_pred, average='weighted')
print(f"F1-Score (weighted): {f1:.3f}")

cv_f1 = cross_val_score(
    rf_pipeline,
    X,
    y,
    cv=3,
    scoring='f1_weighted'
)

print("Mean CV F1-Score:", cv_f1.mean())

from sklearn.model_selection import cross_val_score

acc_scores = cross_val_score(
    rf_pipeline,
    X,
    y,
    cv=5,
    scoring='accuracy'
)

print("Mean Accuracy:", acc_scores.mean() * 100)

from sklearn.model_selection import GridSearchCV

param_grid = {
    'rf__n_estimators': [100, 200, 300],
    'rf__max_depth': [None, 5, 10, 20],
    'rf__min_samples_split': [2, 5, 10],
    'rf__min_samples_leaf': [1, 2, 4]
}

grid = GridSearchCV(
    rf_pipeline,
    param_grid,
    scoring='f1_weighted',
    cv=3
)

grid.fit(X_train, y_train)

print("Best parameters:", grid.best_params_)

best_model = grid.best_estimator_

import pandas as pd

importances = best_model.named_steps['rf'].feature_importances_
feature_names = X.columns

feature_importance = pd.Series(importances, index=feature_names)
print(feature_importance.sort_values(ascending=False))

important_features = feature_importance[feature_importance > 0.01].index
X_reduced = X[important_features]

class_weight='balanced'

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

smote_pipeline = ImbPipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('smote', SMOTE(random_state=42)),
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier(
        n_estimators=200,
        random_state=42
    ))
])

from sklearn.ensemble import GradientBoostingClassifier

gb_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler()),
    ('gb', GradientBoostingClassifier(random_state=42))
])

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

accuracy = rf_pipeline.score(X_test, y_test)
print(f"Accuracy: {accuracy * 100:.2f}%")

from sklearn.model_selection import cross_val_score

acc_scores = cross_val_score(
    rf_pipeline,
    X,
    y,
    cv=5,
    scoring='accuracy'
)

print(f"Mean Accuracy: {acc_scores.mean() * 100:.2f}%")

from sklearn.metrics import accuracy_score, f1_score

print(f"Accuracy (%): {accuracy_score(y_test, y_pred)*100:.2f}")
print(f"F1-score (weighted): {f1_score(y_test, y_pred, average='weighted'):.3f}")
import joblib
# For Random Forest
joblib.dump(rf_pipeline, "rf_lie_model.pkl")  # saves the trained Random Forest pipeline